{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data from: https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193700745?position=39&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=bvNUgUaVN7N8AAhpAYIpwg%3D%3D\n",
      "Data saved to linkedin_jobs_data.json\n",
      "Job data successfully saved to JSON\n",
      "Scraping data from: https://www.linkedin.com/jobs/view/data-scientist-at-transunion-4193702494?position=49&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=%2FYy7oIZpscjM0m4wspkC1A%3D%3D\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 49\u001b[0m, in \u001b[0;36mscrape_linkedin_job\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwebdriver_manager\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchrome\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChromeDriverManager\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchrome\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Service\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'webdriver_manager'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 302\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Please enter a valid LinkedIn job posting URL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    300\u001b[0m     exit(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 302\u001b[0m job_data \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_linkedin_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# Check if there was an error\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m job_data:\n",
      "Cell \u001b[1;32mIn[1], line 55\u001b[0m, in \u001b[0;36mscrape_linkedin_job\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     52\u001b[0m         driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(service\u001b[38;5;241m=\u001b[39mservice, options\u001b[38;5;241m=\u001b[39mchrome_options)\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;66;03m# Fall back to the older method\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m         driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchrome_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError initializing Chrome driver: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\BigDataIntelligence\\test\\test\\.venv\\lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[0;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbrowser_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrowserName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvendor_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\BigDataIntelligence\\test\\test\\.venv\\lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:66\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     57\u001b[0m executor \u001b[38;5;241m=\u001b[39m ChromiumRemoteConnection(\n\u001b[0;32m     58\u001b[0m     remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[0;32m     59\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mbrowser_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m     ignore_proxy\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39m_ignore_local_proxy,\n\u001b[0;32m     63\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquit()\n",
      "File \u001b[1;32md:\\BigDataIntelligence\\test\\test\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:250\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, command_executor, keep_alive, file_detector, options, locator_converter, web_element_cls, client_config)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authenticator_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_client()\n\u001b[1;32m--> 250\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcapabilities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fedcm \u001b[38;5;241m=\u001b[39m FedCM(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_websocket_connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\BigDataIntelligence\\test\\test\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:342\u001b[0m, in \u001b[0;36mWebDriver.start_session\u001b[1;34m(self, capabilities)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new session with the desired capabilities.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \n\u001b[0;32m    335\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m    - A capabilities dict to start the session with.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    341\u001b[0m caps \u001b[38;5;241m=\u001b[39m _create_caps(capabilities)\n\u001b[1;32m--> 342\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNEW_SESSION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaps\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaps \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\BigDataIntelligence\\test\\test\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:427\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    425\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32md:\\BigDataIntelligence\\test\\test\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:404\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    402\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    403\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\BigDataIntelligence\\test\\test\\.venv\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:428\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    425\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 428\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\BigDataIntelligence\\test\\test\\.venv\\lib\\site-packages\\urllib3\\_request_methods.py:143\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m    136\u001b[0m         method,\n\u001b[0;32m    137\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[0;32m    141\u001b[0m     )\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[0;32m    144\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m    145\u001b[0m     )\n",
      "File \u001b[1;32md:\\BigDataIntelligence\\test\\test\\.venv\\lib\\site-packages\\urllib3\\_request_methods.py:278\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[0;32m    276\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32md:\\BigDataIntelligence\\test\\test\\.venv\\lib\\site-packages\\urllib3\\poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32md:\\BigDataIntelligence\\test\\test\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\BigDataIntelligence\\test\\test\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32md:\\BigDataIntelligence\\test\\test\\.venv\\lib\\site-packages\\urllib3\\connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "\n",
    "\n",
    "def scrape_linkedin_job(url):\n",
    "    \"\"\"\n",
    "    Scrape job details from a LinkedIn job posting\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL of the LinkedIn job posting\n",
    "        \n",
    "    Returns:\n",
    "        dict: Job details including title, company, location, description, etc.\n",
    "    \"\"\"\n",
    "    # Validate URL\n",
    "    if not url.startswith(\"http\"):\n",
    "        url = \"https://\" + url\n",
    "        \n",
    "    # Ensure the URL is properly formatted for LinkedIn job posts\n",
    "    if \"linkedin.com\" not in url:\n",
    "        print(\"Warning: This doesn't appear to be a LinkedIn URL\")\n",
    "        return {\"error\": \"Invalid LinkedIn URL\"}\n",
    "        \n",
    "    # Setup Chrome options for headless browsing\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless=new\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "    chrome_options.add_argument(\"--disable-notifications\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    # Add a user agent to avoid detection\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "    \n",
    "    # Initialize the driver with error handling\n",
    "    try:\n",
    "        # Try the newer method first (for newer Selenium versions)\n",
    "        try:\n",
    "            from webdriver_manager.chrome import ChromeDriverManager\n",
    "            from selenium.webdriver.chrome.service import Service\n",
    "            service = Service(ChromeDriverManager().install())\n",
    "            driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        except Exception:\n",
    "            # Fall back to the older method\n",
    "            driver = webdriver.Chrome(options=chrome_options)\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Chrome driver: {e}\")\n",
    "        print(\"Try updating your ChromeDriver to match your Chrome version\")\n",
    "        return {\"error\": \"ChromeDriver initialization failed\"}\n",
    "    \n",
    "    try:\n",
    "        # Navigate to the job posting\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for the page to load\n",
    "        time.sleep(random.uniform(3, 5))\n",
    "        \n",
    "        # Try to click the \"Show more\" button to expand the job description if it exists\n",
    "        try:\n",
    "            show_more_button = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, \".show-more-less-html__button\"))\n",
    "            )\n",
    "            show_more_button.click()\n",
    "            time.sleep(1)  # Give time for the description to expand\n",
    "        except:\n",
    "            pass  # If button is not found or not clickable, just continue\n",
    "        \n",
    "        # Get the page source after JavaScript execution\n",
    "        page_source = driver.page_source\n",
    "        \n",
    "        # Parse the HTML with BeautifulSoup\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "        # Extract job details\n",
    "        job_data = {}\n",
    "        \n",
    "        # Job title\n",
    "        try:\n",
    "            job_data['title'] = soup.select_one('.top-card-layout__title').text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                job_data['title'] = soup.select_one('h1.topcard__title').text.strip()\n",
    "            except:\n",
    "                job_data['title'] = \"Not found\"\n",
    "        \n",
    "        # Company name\n",
    "        try:\n",
    "            job_data['company'] = soup.select_one('.topcard__org-name-link').text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                job_data['company'] = soup.select_one('.top-card-layout__card .topcard__flavor-row span:not(.location)').text.strip()\n",
    "            except:\n",
    "                try:\n",
    "                    job_data['company'] = soup.select_one('.topcard__org-name').text.strip()\n",
    "                except:\n",
    "                    job_data['company'] = \"Not found\"\n",
    "        \n",
    "        # Location\n",
    "        try:\n",
    "            job_data['location'] = soup.select_one('.topcard__flavor--bullet').text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                job_data['location'] = soup.select_one('.top-card-layout__card .topcard__flavor-row .location').text.strip()\n",
    "            except:\n",
    "                try:\n",
    "                    job_data['location'] = soup.select_one('.topcard__subline-location').text.strip()\n",
    "                except:\n",
    "                    job_data['location'] = \"Not found\"\n",
    "                \n",
    "        # Posted date\n",
    "        try:\n",
    "            job_data['posted_date'] = soup.select_one('.posted-time-ago__text').text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                job_data['posted_date'] = soup.select_one('.top-card-layout__card .topcard__flavor-row span.posted-time-ago__text').text.strip()\n",
    "            except:\n",
    "                try:\n",
    "                    job_data['posted_date'] = soup.select_one('.topcard__flavor--metadata').text.strip()\n",
    "                except:\n",
    "                    job_data['posted_date'] = \"Not found\"\n",
    "        \n",
    "        # Job description\n",
    "        try:\n",
    "            job_data['description'] = soup.select_one('.description__text').text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                job_data['description'] = soup.select_one('.show-more-less-html__markup').text.strip()\n",
    "            except:\n",
    "                try:\n",
    "                    # Try a more generic approach\n",
    "                    description_div = soup.select_one('div[class*=\"description\"]')\n",
    "                    if description_div:\n",
    "                        job_data['description'] = description_div.text.strip()\n",
    "                    else:\n",
    "                        job_data['description'] = \"Not found\"\n",
    "                except:\n",
    "                    job_data['description'] = \"Not found\"\n",
    "        \n",
    "        # Job criteria (seniority, employment type, job function, industries)\n",
    "        job_criteria = {}\n",
    "        criteria_section = soup.select('.description__job-criteria-item')\n",
    "        \n",
    "        for criteria in criteria_section:\n",
    "            try:\n",
    "                criteria_header = criteria.select_one('.description__job-criteria-subheader').text.strip()\n",
    "                criteria_value = criteria.select_one('.description__job-criteria-text').text.strip()\n",
    "                job_criteria[criteria_header] = criteria_value\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        job_data['criteria'] = job_criteria\n",
    "        \n",
    "        # Get skills\n",
    "        # try:\n",
    "        #     skills = soup.select('.skill-pill')\n",
    "        #     job_data['skills'] = [skill.text.strip() for skill in skills]\n",
    "        # except:\n",
    "        #     job_data['skills'] = []\n",
    "            \n",
    "        # Get salary information if available\n",
    "        try:\n",
    "            job_data['salary'] = soup.select_one('.compensation__salary').text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                salary_element = soup.select_one('div[class*=\"salary\"]')\n",
    "                if salary_element:\n",
    "                    job_data['salary'] = salary_element.text.strip()\n",
    "                else:\n",
    "                    # Try to find salary in the description\n",
    "                    desc_text = job_data['description'].lower()\n",
    "                    salary_idx = desc_text.find(\"salary range\")\n",
    "                    if salary_idx > -1:\n",
    "                        # Extract approximately 100 characters after \"salary range\"\n",
    "                        snippet = desc_text[salary_idx:salary_idx+150]\n",
    "                        job_data['salary'] = snippet\n",
    "                    else:\n",
    "                        job_data['salary'] = \"Not found\"\n",
    "            except:\n",
    "                job_data['salary'] = \"Not found\"\n",
    "        \n",
    "        # Number of applicants \n",
    "        try:\n",
    "            job_data['applicants'] = soup.select_one('.num-applicants__caption').text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                applicants_element = soup.select_one('span[class*=\"applicant\"]')\n",
    "                if applicants_element:\n",
    "                    job_data['applicants'] = applicants_element.text.strip()\n",
    "                else:\n",
    "                    job_data['applicants'] = \"Not found\"\n",
    "            except:\n",
    "                job_data['applicants'] = \"Not found\"\n",
    "        \n",
    "        return job_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "    \n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "# def save_to_json(job_data, filename=\"linkedin_job_data.json\"):\n",
    "#     \"\"\"Save job data to a JSON file\"\"\"\n",
    "#     with open(filename, 'w', encoding='utf-8') as f:\n",
    "#         json.dump(job_data, f, indent=4, ensure_ascii=False)\n",
    "#     print(f\"Data saved to {filename}\")\n",
    "\n",
    "def save_to_json(job_data_list, filename=\"linkedin_jobs_data.json\"):\n",
    "    \"\"\"\n",
    "    Save multiple job data entries to a JSON file\n",
    "    \n",
    "    Args:\n",
    "        job_data_list (list): List of job data dictionaries\n",
    "        filename (str): Output JSON filename\n",
    "    \"\"\"\n",
    "    # Ensure job_data_list is a list\n",
    "    if not isinstance(job_data_list, list):\n",
    "        job_data_list = [job_data_list]\n",
    "        \n",
    "    # Check if file already exists to append instead of overwrite\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            existing_data = json.load(f)\n",
    "            \n",
    "            # Ensure existing_data is a list\n",
    "            if not isinstance(existing_data, list):\n",
    "                existing_data = [existing_data]\n",
    "                \n",
    "            # Combine the lists\n",
    "            combined_data = existing_data + job_data_list\n",
    "            \n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        # File doesn't exist or is invalid, use only new data\n",
    "        combined_data = job_data_list\n",
    "        \n",
    "    # Write the combined data\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(combined_data, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "def scrape_multiple_jobs(job_urls, output_json=\"linkedin_jobs.json\"):\n",
    "    \"\"\"\n",
    "    Scrape multiple job postings and save combined results to JSON\n",
    "    \n",
    "    Args:\n",
    "        job_urls (list): List of LinkedIn job posting URLs\n",
    "        output_json (str): Filename for JSON output\n",
    "    \"\"\"\n",
    "    all_jobs = []\n",
    "    \n",
    "    for i, url in enumerate(job_urls):\n",
    "        print(f\"Scraping job {i+1}/{len(job_urls)}: {url}\")\n",
    "        job_data = scrape_linkedin_job(url)\n",
    "        \n",
    "        if \"error\" not in job_data:\n",
    "            all_jobs.append(job_data)\n",
    "            print(f\"Successfully scraped job data for: {job_data.get('title', 'Unknown Title')}\")\n",
    "        else:\n",
    "            print(f\"Failed to scrape job: {job_data.get('error', 'Unknown error')}\")\n",
    "        \n",
    "        # Add a random delay between requests to avoid detection\n",
    "        if i < len(job_urls) - 1:\n",
    "            delay = random.uniform(3, 8)\n",
    "            print(f\"Waiting {delay:.2f} seconds before next request...\")\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    # Save combined results to JSON\n",
    "    with open(output_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_jobs, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"All job data saved to {output_json}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # For single job scraping\n",
    "        # job_url = f\"https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193700745/?position=39&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=bvNUgUaVN7N8AAhpAYIpwg%3D%3D\"\n",
    "        with open(\"parsed_links.json\", \"r\") as file:\n",
    "           data = json.load(file)     \n",
    "        for url in data:\n",
    "            job_url = url['url']\n",
    "            print(f\"Scraping data from: {job_url}\")\n",
    "            \n",
    "            # Validate URL before proceeding\n",
    "            if not job_url or len(job_url) < 10:\n",
    "                print(\"Error: Please enter a valid LinkedIn job posting URL\")\n",
    "                exit(1)\n",
    "                \n",
    "            job_data = scrape_linkedin_job(job_url)\n",
    "            \n",
    "            # Check if there was an error\n",
    "            if \"error\" in job_data:\n",
    "                print(f\"Error occurred: {job_data['error']}\")\n",
    "                exit(1)\n",
    "                \n",
    "            # Save the data to JSON only\n",
    "            save_to_json(job_data)\n",
    "            print(\"Job data successfully saved to JSON\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"parsed_links.json\", \"r\") as file:\n",
    "#     data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193700745?position=39&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=bvNUgUaVN7N8AAhpAYIpwg%3D%3D\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-transunion-4193702494?position=49&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=%2FYy7oIZpscjM0m4wspkC1A%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193700751?position=30&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=j5gAN37Nv%2B2dC87VHb6coA%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193299984?position=17&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=kOYPCY7Ov4QKoHrBCYgx4Q%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193704313?position=34&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=9MWqvZFnY4UWD%2Bbh0ZWouw%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193299980?position=28&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=87vcN4r%2B68J6Ud9GROQzoA%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193704314?position=32&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=IATdiEf7TlgiRz5N91XxWg%3D%3D\n",
      "https://www.linkedin.com/jobs/view/data-engineer-ii-gtech-users-and-products-at-google-4193299940?position=26&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=%2BzfwAgfT2u5qOfILeTidVw%3D%3D\n",
      "https://www.linkedin.com/jobs/view/data-science-manager-at-gtn-technical-staffing-4184537622?position=51&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=Fzmit37D4eMGrpOjiktnCg%3D%3D\n",
      "https://www.linkedin.com/jobs/view/senior-power-bi-developer-remote-at-hilton-grand-vacations-4197807085?position=55&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=J5v9lnco2qnvkrQBWxtZ%2BA%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193706056?position=23&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=tPR3l7XxqMTq%2BWipU%2BbiWQ%3D%3D\n",
      "https://www.linkedin.com/jobs/view/senior-analyst-finance-data-specialist-at-kpmg-us-4196239606?position=7&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=s25kWZyXEsj%2FijoVeO%2FFDw%3D%3D\n",
      "https://www.linkedin.com/jobs/view/senior-specialist-deal-advisory-strategy-data-science-at-kpmg-us-4196245156?position=46&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=sS0gSFz5lpTSaTxlV2mpFg%3D%3D\n",
      "https://www.linkedin.com/jobs/view/senior-analyst-finance-data-specialist-at-kpmg-us-4196235956?position=9&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=b7OZV%2Fn49wtkmehUhQXSkw%3D%3D\n",
      "https://www.linkedin.com/jobs/view/desk-analyst-at-nabidex-4193229901?position=5&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=PQXdTKgEzzds1307Tz9t0w%3D%3D\n",
      "https://www.linkedin.com/jobs/view/senior-analyst-finance-data-specialist-at-kpmg-us-4196235996?position=12&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=LxCknXEJuNuQWJJ4ytgFJA%3D%3D\n",
      "https://www.linkedin.com/jobs/view/business-systems-analyst-senior-at-gallagher-4197687913?position=50&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=5E8K6EwkNBD5dmpwnEX4Ng%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193703359?position=35&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=YgKrh9%2FFIC9DD1kPq%2F9M0Q%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193705275?position=36&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=VF3582c2OUbjwR597P71qg%3D%3D\n",
      "https://www.linkedin.com/jobs/view/sr-business-intelligence-developer-at-yoh-a-day-zimmermann-company-4197804588?position=42&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=lfahqNRBXcHCPf09OdHVrg%3D%3D\n",
      "https://www.linkedin.com/jobs/view/senior-analyst-finance-data-specialist-at-kpmg-us-4196238711?position=10&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=xt4JdEMUSgXn5XH4WujRQA%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193702427?position=45&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=ihaEfg9li0pvXZILnKWTYw%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193703336?position=31&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=OyJlji9xGkluG6Bp14BQDw%3D%3D\n",
      "https://www.linkedin.com/jobs/view/sr-bi-developer-powerbi-fabric-at-gtn-technical-staffing-4192959183?position=52&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=ONkOChwjpSiYpgY7lazX6g%3D%3D\n",
      "https://www.linkedin.com/jobs/view/senior-systems-analyst-at-bausch-%2B-lomb-4197688790?position=53&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=XyaEADUKeugDKOzFGzRUhA%3D%3D\n",
      "https://www.linkedin.com/jobs/view/it-communications-analyst-l-at-county-of-riverside-4193701691?position=58&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=XCbFMdJ3TN5vbZl3Syzzlw%3D%3D\n",
      "https://www.linkedin.com/jobs/view/data-analyst-data-manager-at-stanford-university-school-of-medicine-4193707280?position=3&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=jjq9xtdQk59N9v8A%2B5Gr6A%3D%3D\n",
      "https://www.linkedin.com/jobs/view/senior-analyst-finance-data-specialist-at-kpmg-us-4196239644?position=14&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=F5pNoxS4rVrsyF9OchU4gQ%3D%3D\n",
      "https://www.linkedin.com/jobs/view/senior-specialist-federal-data-engineer-at-kpmg-us-4196234852?position=56&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=B2Qd%2FFciQaT4kd9tnbJJ%2FA%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193703358?position=24&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=D%2B4YQs0PThZKNa6Lmzw6cw%3D%3D\n",
      "https://www.linkedin.com/jobs/view/insights-analyst-at-crossmark-4197695065?position=4&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=GlC%2Book2k8rjsJTfBJUd4Q%3D%3D\n",
      "https://www.linkedin.com/jobs/view/pmo-analyst-at-leidos-4196242388?position=44&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=ibdV%2BMa6A31Q26QT199Bmg%3D%3D\n",
      "https://www.linkedin.com/jobs/view/data-engineer-sub-same-day-ssd-engineering-at-amazon-4197691546?position=19&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=TemyYMnTUdZ5j7b%2Fht1Mvw%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193706058?position=47&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=jstvOdFy3W7GvSxARkoGsw%3D%3D\n",
      "https://www.linkedin.com/jobs/view/senior-analyst-at-kpmg-us-4196241360?position=57&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=DKyxdLWFfmsK7cElQ9sg%2FQ%3D%3D\n",
      "https://www.linkedin.com/jobs/view/data-engineer-sub-same-day-ssd-engineering-at-amazon-4197689531?position=20&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=V%2BQE6Kh39FVFVXHVrP%2FkQA%3D%3D\n",
      "https://www.linkedin.com/jobs/view/data-engineering-intern-at-age-of-learning-4197691403?position=11&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=etR1fn9WANyTZhvjpggAhw%3D%3D\n",
      "https://www.linkedin.com/jobs/view/analyst-i-at-kpmg-us-4196238884?position=8&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=%2FzN6EZVUoHZP%2FqBdZhmphg%3D%3D\n",
      "https://www.linkedin.com/jobs/view/data-engineer-sub-same-day-ssd-engineering-at-amazon-4197689532?position=21&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=ck%2FCukAmN730g%2FzDiI6Y7A%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193700752?position=27&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=MLVLLPJ39Y0jyofTw%2B8ipQ%3D%3D\n",
      "https://www.linkedin.com/jobs/view/machine-learning-engineer-fine-tuning-at-ai-fund-4193705390?position=40&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=czYfNXhzifBzau%2Bqxz7kDQ%3D%3D\n",
      "https://www.linkedin.com/jobs/view/salesforce-developer-at-drive-social-media-4197686950?position=59&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=RUrLhnIn9KAJSzqThuYm7g%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193700753?position=18&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=g2lNLNTDJEWTnz2brFH0%2FA%3D%3D\n",
      "https://www.linkedin.com/jobs/view/data-engineer-sub-same-day-ssd-engineering-at-amazon-4197692428?position=15&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=zRx%2FbbIjn6UmY6M5Rahj8Q%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193702429?position=48&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=u5cJF%2BAAxkrRnu7IG41ung%3D%3D\n",
      "https://www.linkedin.com/jobs/view/senior-analyst-finance-data-specialist-at-kpmg-us-4196244029?position=13&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=iKtbWdJY3EYzJqF%2Bdc%2BEbA%3D%3D\n",
      "https://www.linkedin.com/jobs/view/senior-manager-customer-growth-data-and-analytics-at-american-express-4197695000?position=22&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=F8BOvxNkNg%2FHdGtGg%2B0U6g%3D%3D\n",
      "https://www.linkedin.com/jobs/view/sr-media-data-analyst-25-04338-at-akraya-inc-4196238274?position=2&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=6yf7ieYOjO5xfoqvMTLzLQ%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193703327?position=25&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=N4lSdBnIjR6BvYUMAp3Snw%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193299963?position=29&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=QqicfHbLAPDzeD9KYDO21Q%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193702428?position=37&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=EvwZeKE71HUzWzy7YjCu2A%3D%3D\n",
      "https://www.linkedin.com/jobs/view/data-discovery-engineer-at-radnet-4192531268?position=43&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=GCC%2F1h4k%2FIq4nzU7YT6IOQ%3D%3D\n",
      "https://www.linkedin.com/jobs/view/marketing-data-analyst-at-teepublic-4193704627?position=1&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=zgs7XZ8WJThih3zpXS0Z2A%3D%3D\n",
      "https://www.linkedin.com/jobs/view/data-science-analytics-intern-at-age-of-learning-4197696005?position=6&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=Nev8b5iNuDwZgl0Kag56KA%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193704312?position=38&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=vMZeuZzNjC7vLqgbNFAtVw%3D%3D\n",
      "https://www.linkedin.com/jobs/view/lead-specialist-deal-advisory-strategy-data-science-at-kpmg-us-4196244152?position=41&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=y%2BoobeoUz2MddBhIp%2FxXOQ%3D%3D\n",
      "https://www.linkedin.com/jobs/view/data-engineer-sub-same-day-ssd-engineering-at-amazon-4197696155?position=16&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=e8ZN9EN3Nkkc%2FwB%2Fs2NcUg%3D%3D\n",
      "https://www.linkedin.com/jobs/view/sap-ixp-intern-ai-engineer-at-sap-4193706329?position=54&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=e9%2F6fpqfbbqPhRTYKfh8cw%3D%3D\n",
      "https://www.linkedin.com/jobs/view/data-scientist-at-g2-4197693279?position=60&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=NdTQ%2Fy2f%2FiG5QKXlF%2BKRfw%3D%3D\n",
      "https://www.linkedin.com/jobs/view/avp-digital-measurement-analytics-at-synchrony-4193705304?position=33&pageNum=0&refId=FCkmm70%2FC892Nn1Wbgg%2B8A%3D%3D&trackingId=4paS57nJj4%2BW%2FOIkC9JPKg%3D%3D\n"
     ]
    }
   ],
   "source": [
    "# for url in data:\n",
    "#     print(url['url'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
